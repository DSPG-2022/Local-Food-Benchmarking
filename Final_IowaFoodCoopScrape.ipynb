{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_IowaFoodCoopScrape.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DSPG-2022/Local-Food-Benchmarking/blob/main/Final_IowaFoodCoopScrape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o9abPusqTqxE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27b8f5a3-7033-484b-84c6-262155da7f96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 0 B/88.7 kB 0%] [Connected to cloud.r-pro\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 88.7 kB/88.7 kB 100%] [Connected to cloud\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "\r                                                                               \rGet:4 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "\r                                                                               \rHit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "\r0% [3 InRelease 64.9 kB/88.7 kB 73%] [Waiting for headers] [Waiting for headers\r0% [2 InRelease gpgv 242 kB] [3 InRelease 70.7 kB/88.7 kB 80%] [Waiting for hea\r                                                                               \r0% [2 InRelease gpgv 242 kB] [Waiting for headers] [Waiting for headers]\r                                                                        \rGet:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Ign:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:9 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:11 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,861 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,521 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [22.8 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,006 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,294 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,040 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,297 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n",
            "Fetched 12.3 MB in 3s (3,843 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 49 not upgraded.\n",
            "Need to get 89.8 MB of archives.\n",
            "After this operation, 302 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 101.0.4951.64-0ubuntu0.18.04.1 [1,142 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 101.0.4951.64-0ubuntu0.18.04.1 [78.5 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 101.0.4951.64-0ubuntu0.18.04.1 [4,980 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 101.0.4951.64-0ubuntu0.18.04.1 [5,153 kB]\n",
            "Fetched 89.8 MB in 2s (51.0 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 155639 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_101.0.4951.64-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_101.0.4951.64-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (101.0.4951.64-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting selenium\n",
            "  Downloading selenium-4.2.0-py3-none-any.whl (983 kB)\n",
            "\u001b[K     |████████████████████████████████| 983 kB 23.2 MB/s \n",
            "\u001b[?25hCollecting trio-websocket~=0.9\n",
            "  Downloading trio_websocket-0.9.2-py3-none-any.whl (16 kB)\n",
            "Collecting trio~=0.17\n",
            "  Downloading trio-0.21.0-py3-none-any.whl (358 kB)\n",
            "\u001b[K     |████████████████████████████████| 358 kB 48.9 MB/s \n",
            "\u001b[?25hCollecting urllib3[secure,socks]~=1.26\n",
            "  Downloading urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "\u001b[K     |████████████████████████████████| 138 kB 58.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.10)\n",
            "Collecting outcome\n",
            "  Downloading outcome-1.2.0-py2.py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (21.4.0)\n",
            "Collecting async-generator>=1.9\n",
            "  Downloading async_generator-1.10-py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.7/dist-packages (from trio~=0.17->selenium) (2.4.0)\n",
            "Collecting sniffio\n",
            "  Downloading sniffio-1.2.0-py3-none-any.whl (10 kB)\n",
            "Collecting wsproto>=0.14\n",
            "  Downloading wsproto-1.1.0-py3-none-any.whl (24 kB)\n",
            "Collecting pyOpenSSL>=0.14\n",
            "  Downloading pyOpenSSL-22.0.0-py2.py3-none-any.whl (55 kB)\n",
            "\u001b[K     |████████████████████████████████| 55 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting cryptography>=1.3.4\n",
            "  Downloading cryptography-37.0.2-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (2022.6.15)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (1.15.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=1.3.4->urllib3[secure,socks]~=1.26->selenium) (2.21)\n",
            "Collecting h11<1,>=0.9.0\n",
            "  Downloading h11-0.13.0-py3-none-any.whl (58 kB)\n",
            "\u001b[K     |████████████████████████████████| 58 kB 5.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from h11<1,>=0.9.0->wsproto>=0.14->trio-websocket~=0.9->selenium) (4.1.1)\n",
            "Installing collected packages: sniffio, outcome, h11, cryptography, async-generator, wsproto, urllib3, trio, pyOpenSSL, trio-websocket, selenium\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "requests 2.23.0 requires urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1, but you have urllib3 1.26.9 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed async-generator-1.10 cryptography-37.0.2 h11-0.13.0 outcome-1.2.0 pyOpenSSL-22.0.0 selenium-4.2.0 sniffio-1.2.0 trio-0.21.0 trio-websocket-0.9.2 urllib3-1.26.9 wsproto-1.1.0\n",
            "\u001b[K     |████████████████████████████████| 57 kB 4.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!apt-get update \n",
        "!apt install chromium-chromedriver\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "!pip install selenium\n",
        "!pip install kora -q\n",
        "#Import Selenium tools library\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
        "import os\n",
        "from selenium import webdriver\n",
        "from selenium.webdriver.support.ui import WebDriverWait\n",
        "from selenium.webdriver.chrome.options import Options\n",
        "from selenium.webdriver.common.by import By\n",
        "from selenium.webdriver.support import expected_conditions as EC\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Import beautifulSoup and Pandas\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "###### Create a data frame with all the columns needed\n",
        "\n",
        "dfObj = pd.DataFrame(columns=['Item_Category','Item_Name','Producer', 'Unit', 'Price'])#create columns for all data\n",
        "#iterate through multiple pages for range\n",
        "for i in range(6):\n",
        "\n",
        "  #insert url for website needed to be scraped\n",
        "  html_text = requests.get(\"https://shop.iowafood.coop/product-search?IDCat=11&IdxPage={}\".format(i)).text\n",
        "\n",
        " #developer view to find where desired information is located\n",
        "  soup = BeautifulSoup(html_text, \"lxml\")\n",
        "  top_level = soup.find('div', class_ = 'row row-cols-1 row-cols-sm-2 row-cols-lg-3 no-gutters')\n",
        "  items = top_level.find_all('div', class_ = 'col')\n",
        "  print(len(items))\n",
        "\n",
        "###############################################################################\n",
        "#divide needed information into variables\n",
        "#insert location code in variables from developer view for selected website\n",
        "  for item in items:\n",
        "    item_name = (item.find('a', class_ = \"Product font-size-120 font-weight-bold\")).string\n",
        "\n",
        "    item_name = item_name.strip()\n",
        "\n",
        "    footer = item.find('div', class_ = 'Foot').find (\"div\", class_ = \"d-flex flex-row justify-content-between\")\n",
        "    footer.find_all('div')\n",
        "    divs = [c for c in footer.find_all('div')]\n",
        "    item_unit = divs[0].string\n",
        "    item_price = divs[1].string\n",
        "\n",
        "\n",
        "    item_test = item_unit.split('\\n')\n",
        "\n",
        "    item_category=item.find('a', class_=\"Subcat\").string\n",
        "\n",
        "    item_category=item_category.strip()\n",
        "\n",
        "    item_producer=item.find('a', class_ = \"Producer\").string\n",
        "\n",
        "    item_producer=item_producer.strip()\n",
        "\n",
        "  ################ append the items in the dataframe ##########################################\n",
        "\n",
        "    dfObj = dfObj.append({'Item_Name':item_name , 'Unit':item_unit,'Item_category':item_category,'Producer':item_producer,'Price':item_price}, ignore_index=True)\n",
        "\n",
        "  ##############################################################################################\n",
        "\n",
        "  ########### save to excel file \n",
        "\n",
        "dfObj.to_excel('honey_raw_data.xls',sheet_name= \"Sheet1\", index=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnDJxoq56ng_",
        "outputId": "45160477-49de-4298-8f5a-d01a267ae3d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "24\n",
            "13\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:73: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PiTo3uvIjQQF"
      }
    }
  ]
}